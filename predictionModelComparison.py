# -*- coding: utf-8 -*-
"""Homework2Done.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qpzQ5vEldg-NRQJ5Z1XyssmOrNueSNdq

Homework 2
---
**Due Nov. 30 (Tue) by end of the day.**

Do all your work on this notebook. Submit your homework by uploading the notebook file to moodle. Your submission notebook should contain:

- Code
- Output from running your code (printouts)
- Answer to any questions or any comments (type in a markdown cell)

***
"""

# Commented out IPython magic to ensure Python compatibility.
# %pylab inline
import warnings
warnings.filterwarnings('ignore')

from sklearn.datasets import load_files
from sklearn.model_selection import train_test_split

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, f1_score

"""### The movie review dataset"""

import cloudpickle as cp
from urllib.request import urlopen
dataset = cp.load(urlopen("https://drive.google.com/uc?export=download&id=1tqjekAEy_SM_sJUvjIBbajp6I-_WmHgj"))

print(len(dataset.target))
print(dataset.data[220]) #List of strings, the whole article, 2000 reviews, 50/50 neg and pos

docs_train, docs_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.25, random_state=123)

"""Task 1 
---
Use TfidfVectorizer to fit_transform the training data (docs_train) and then transform the test data (docs_test)
"""

from sklearn.feature_extraction.text import TfidfVectorizer
tf = TfidfVectorizer()

rev_fit= tf.fit_transform(docs_train)

rev_tf = tf.transform(docs_test)

"""Task 2 
---
Build a SVC model to predict whether a movie review is positive or negative. Test the model accuracy on the test data. Try different values (0.01, 0.1, 1, 10) for the hyper parameter 'C' and print out the model accuracy for each of the parameter value.
"""

from sklearn.svm import SVC

svc = SVC(kernel = 'linear')

for c in [0.01, 0.1, 1, 10]:
    model = SVC(C=c)
    model.fit(rev_fit, y_train)
    pred = model.predict(rev_tf)
    print("Accuracy score for" , c ,": " , accuracy_score(y_test, pred))

"""Task 3
---
Naive Bayes is a prediction model based on applying Bayes’ theorem with the “naive” assumption of conditional independence between every pair of features given the value of the class variable.

Build a Naive Bayes model to predict whether a movie review is positive or negative. Test the model accuracy on the test data.
"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score
nb = MultinomialNB()
nb.fit(rev_fit, y_train)

pred = nb.predict(rev_tf)

accuracy_score(y_test, pred)

"""Task 4
---
A random forest is a ensemble (collective) model that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.

Build a random forest model to predict whether a movie review is positive or negative. Test the model accuracy on the test data. Try different values (20, 100, 500) for the hyper parameter 'n_estimators', i.e., the number of decision trees in the ensemble, and print out the model accuracy for each of the parameter value.
"""

from sklearn.ensemble import RandomForestClassifier
for n in [20, 100, 500]:
  rf = RandomForestClassifier(n_estimators = n, random_state = 69)
  rf.fit(rev_fit, y_train)
  pred = rf.predict(rev_tf)
  print("Accuracy score for" , n ,": " , accuracy_score(y_test, pred))

"""### From the above tasks, you can observe that different models and different choice of hyper-parameter values can lead to quite different prediction performance. What is the model (and hyper-parameter) among the above that gives the best prediction? What is the worst?"""



"""Overall, the SVC model gave the best performance, and the worst. the parameters 0.01 and 0.1 gave a accuracy score of just under 50%, while the parameter 100 gave an accuracy score of 82%, enough for first place. Outside of the SVC model, the Random Forest Generator gave a accuracy score of 70%-78%, which is good enough to net it the worst overall."""